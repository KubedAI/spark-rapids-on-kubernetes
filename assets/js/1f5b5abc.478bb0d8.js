"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[748],{1976:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>c,toc:()=>h});var r=s(4848),t=s(8453);const a={sidebar_position:2,sidebar_label:"Benchmarks"},i="Spark RAPIDS Benchmark Execution \ud83d\ude80",c={id:"Benchmarks/benchmarks",title:"Spark RAPIDS Benchmark Execution \ud83d\ude80",description:"This guide provides a step-by-step process to run Spark RAPIDS benchmarks on both CPUs and GPUs. It includes detailed instructions on how to configure, execute, monitor, and compare the results efficiently. The benchmarks will help you assess performance improvements when using GPUs for data processing and machine learning predictions.",source:"@site/docs/Benchmarks/benchmarks.md",sourceDirName:"Benchmarks",slug:"/Benchmarks/",permalink:"/spark-rapids-on-kubernetes/docs/Benchmarks/",draft:!1,unlisted:!1,editUrl:"https://github.com/Kube-dAI/spark-rapids-on-kubernetes/tree/main/packages/create-spark-rapids-on-kubernetes/templates/shared/docs/Benchmarks/benchmarks.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,sidebar_label:"Benchmarks"},sidebar:"docSidebar",previous:{title:"Data Generation",permalink:"/spark-rapids-on-kubernetes/docs/Benchmarks/data-generation"},next:{title:"Observability",permalink:"/spark-rapids-on-kubernetes/docs/observability"}},o={},h=[{value:"Pre-requisites \u2699\ufe0f",id:"pre-requisites-\ufe0f",level:2},{value:"Execute Benchmark on CPUs \ud83d\udda5\ufe0f",id:"execute-benchmark-on-cpus-\ufe0f",level:2},{value:"Execute Benchmark on GPUs \ud83d\udda5\ufe0f\ud83d\udca1",id:"execute-benchmark-on-gpus-\ufe0f",level:2},{value:"Benchmark Results",id:"benchmark-results",level:2},{value:"Final Thoughts \ud83d\udca1",id:"final-thoughts-",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"spark-rapids-benchmark-execution-",children:"Spark RAPIDS Benchmark Execution \ud83d\ude80"})}),"\n",(0,r.jsx)(n.p,{children:"This guide provides a step-by-step process to run Spark RAPIDS benchmarks on both CPUs and GPUs. It includes detailed instructions on how to configure, execute, monitor, and compare the results efficiently. The benchmarks will help you assess performance improvements when using GPUs for data processing and machine learning predictions."}),"\n",(0,r.jsx)(n.p,{children:"Here\u2019s an example of the benchmark results:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"alt text",src:s(5115).A+"",width:"1311",height:"835"})}),"\n",(0,r.jsx)(n.h2,{id:"pre-requisites-\ufe0f",children:"Pre-requisites \u2699\ufe0f"}),"\n",(0,r.jsx)(n.p,{children:"Before you begin, ensure that the following steps are completed:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step1: Generate Test Data \ud83d\udcdd"})}),"\n",(0,r.jsx)(n.p,{children:"Before executing the benchmarks, you need to generate the necessary test data. This data will be stored in an S3 bucket and will be used to configure the Spark Operator for both CPU and GPU jobs."}),"\n",(0,r.jsxs)(n.p,{children:["Follow this ",(0,r.jsx)(n.a,{href:"https://kubedai.github.io/spark-rapids-on-kubernetes/docs/Benchmarks/data-generation",children:"data generation guide"})," for detailed steps on how to generate the data."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step2: Upload the PySpark Script to S3 \ud83d\udcbe"})}),"\n",(0,r.jsx)(n.p,{children:"Upload the benchmark script to the S3 bucket using the following command:"}),"\n",(0,r.jsxs)(n.p,{children:["Replace ",(0,r.jsx)(n.code,{children:"<S3_BUCKET>"})," with your actual S3 bucket name."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"aws s3 cp benchmarks/benchmark/spark-rapids-benchmarks.py s3://<S3_BUCKET>/benchmark/scripts/\n"})}),"\n",(0,r.jsx)(n.h2,{id:"execute-benchmark-on-cpus-\ufe0f",children:"Execute Benchmark on CPUs \ud83d\udda5\ufe0f"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 1: Update S3 Bucket in the Benchmark File \ud83d\udcc2"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Navigate to the root directory of the repository."}),"\n",(0,r.jsxs)(n.li,{children:["Open the file ",(0,r.jsx)(n.code,{children:"benchmarks/benchmark/benchmark-cpu.yaml"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Replace ",(0,r.jsx)(n.code,{children:"<S3_BUCKET>"})," with the actual S3 bucket name."]}),"\n",(0,r.jsx)(n.li,{children:"Save the file."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 2: Run the Benchmark Script \ud83d\ude80"})}),"\n",(0,r.jsx)(n.p,{children:"From your terminal, execute the benchmark job:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f benchmarks/benchmark/benchmark-cpu.yaml\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 3: Monitor the Job Execution \ud83d\udc40"})}),"\n",(0,r.jsx)(n.p,{children:"Monitor the running pods by checking the job status:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl get pods -n data-eng-team\n"})}),"\n",(0,r.jsx)(n.p,{children:"You should see one driver pod and two executor pods."}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsx)(n.p,{children:"The job might take over an hour to complete."})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 4: Verify the Output Results \ud83d\udcca"})}),"\n",(0,r.jsxs)(n.p,{children:["Once the job succeeds, find the results in ",(0,r.jsx)(n.code,{children:"s3://<S3_BUCKET>/benchmark/output/cpu"})]}),"\n",(0,r.jsx)(n.p,{children:"Open the file and review the results."}),"\n",(0,r.jsx)(n.p,{children:"You can also monitor the job in real-time using the Spark History Server:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl port-forward svc/spark-history-server -n spark-history-server 8080:80\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Then, open ",(0,r.jsx)(n.a,{href:"http://localhost:8080",children:"http://localhost:8080"})," in your browser."]}),"\n",(0,r.jsx)(n.p,{children:"After verifying the results, delete the CPU job to free up resources:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl delete -f benchmarks/benchmark/benchmark-cpu.yaml\n"})}),"\n",(0,r.jsx)(n.h2,{id:"execute-benchmark-on-gpus-\ufe0f",children:"Execute Benchmark on GPUs \ud83d\udda5\ufe0f\ud83d\udca1"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 1: Update S3 Bucket in the Benchmark File \ud83d\udcc2"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Navigate to the root directory of the repository."}),"\n",(0,r.jsxs)(n.li,{children:["Open the file ",(0,r.jsx)(n.code,{children:"benchmarks/benchmark/benchmark-gpu.yaml"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Replace ",(0,r.jsx)(n.code,{children:"<S3_BUCKET>"})," with the actual S3 bucket name."]}),"\n",(0,r.jsx)(n.li,{children:"Save the file."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 2: Run the Benchmark Script \ud83d\ude80"})}),"\n",(0,r.jsx)(n.p,{children:"From your terminal, execute the benchmark job:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f benchmarks/benchmark/benchmark-gpu.yaml\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 3: Monitor the Job Execution \ud83d\udc40"})}),"\n",(0,r.jsx)(n.p,{children:"Monitor the running pods by checking the job status:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl get pods -n data-eng-team\n"})}),"\n",(0,r.jsxs)(n.p,{children:["You should see one driver pod running on a CPU and two executor pods running on GPU instances such as ",(0,r.jsx)(n.code,{children:"g5/g6.2xlarge"}),"."]}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsx)(n.p,{children:"The job might take around 22 mins to complete."})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 4: Verify the Output Results \ud83d\udcca"})}),"\n",(0,r.jsxs)(n.p,{children:["Once the job succeeds, find the results in ",(0,r.jsx)(n.code,{children:"s3://<S3_BUCKET>/benchmark/output/gpu"})]}),"\n",(0,r.jsx)(n.p,{children:"Open the file and review the results."}),"\n",(0,r.jsx)(n.p,{children:"You can also monitor the job in real-time using the Spark History Server:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl port-forward svc/spark-history-server -n spark-history-server 8080:80\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Then, open ",(0,r.jsx)(n.a,{href:"http://localhost:8080",children:"http://localhost:8080"})," in your browser."]}),"\n",(0,r.jsx)(n.p,{children:"After verifying the results, delete the CPU job to free up resources:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl delete -f benchmarks/benchmark/benchmark-gpu.yaml\n"})}),"\n",(0,r.jsx)(n.h2,{id:"benchmark-results",children:"Benchmark Results"}),"\n",(0,r.jsx)(n.p,{children:"Here\u2019s a closer look at the benchmark test configuration:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"alt text",src:s(4610).A+"",width:"1004",height:"434"})}),"\n",(0,r.jsx)(n.p,{children:"This chart shows a comparison between CPU and GPU benchmark performance:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"alt text",src:s(6784).A+"",width:"1168",height:"495"})}),"\n",(0,r.jsx)(n.p,{children:"From these results, you can clearly see the performance gains when using GPUs for data processing and machine learning predictions."}),"\n",(0,r.jsx)(n.h2,{id:"final-thoughts-",children:"Final Thoughts \ud83d\udca1"}),"\n",(0,r.jsx)(n.p,{children:"Congratulations! \ud83c\udf89 You\u2019ve successfully executed and compared Spark RAPIDS benchmarks on both CPUs and GPUs. Continue fine-tuning your configurations and exploring further optimizations to improve performance and cost-efficiency."})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},6784:(e,n,s)=>{s.d(n,{A:()=>r});const r=s.p+"assets/images/image-1-b9bb56d3743f7a6518ccb3e6daffbeb8.png"},5115:(e,n,s)=>{s.d(n,{A:()=>r});const r=s.p+"assets/images/image-2-1890379ffb04acc31500f1da4f68f354.png"},4610:(e,n,s)=>{s.d(n,{A:()=>r});const r=s.p+"assets/images/image-ae7aaf6b24d5741eb0670d487370814a.png"},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>c});var r=s(6540);const t={},a=r.createContext(t);function i(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);