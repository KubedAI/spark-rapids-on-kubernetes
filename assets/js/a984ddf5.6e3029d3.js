"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[746],{2031:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>t,metadata:()=>i,toc:()=>d});var a=r(4848),s=r(8453);const t={sidebar_position:1,sidebar_label:"\ud83d\ude80 Spark RAPIDS on GPUs"},o="\u26a1 Spark RAPIDS on GPUs",i={id:"Blueprints/spark-rapids-gpus",title:"\u26a1 Spark RAPIDS on GPUs",description:"Welcome to the Spark RAPIDS on GPUs documentation! This guide will help you execute a Spark RAPIDS job on a Kubernetes cluster using GPUs for accelerated data processing. Let's get started! \ud83d\udca1",source:"@site/docs/Blueprints/spark-rapids-gpus.md",sourceDirName:"Blueprints",slug:"/Blueprints/spark-rapids-gpus",permalink:"/spark-rapids-on-kubernetes/docs/Blueprints/spark-rapids-gpus",draft:!1,unlisted:!1,editUrl:"https://github.com/Kube-dAI/spark-rapids-on-kubernetes/tree/main/packages/create-spark-rapids-on-kubernetes/templates/shared/docs/Blueprints/spark-rapids-gpus.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,sidebar_label:"\ud83d\ude80 Spark RAPIDS on GPUs"},sidebar:"docSidebar",previous:{title:"Spark RAPIDS Blueprints",permalink:"/spark-rapids-on-kubernetes/docs/category/spark-rapids-blueprints"},next:{title:"Spark RAPIDS with YuniKorn",permalink:"/spark-rapids-on-kubernetes/docs/Blueprints/yunikorn-spark-rapids"}},l={},d=[{value:"\u2705 Pre-requisites",id:"-pre-requisites",level:2},{value:"\ud83d\udcbb Executing the Spark RAPIDS Sample Job",id:"-executing-the-spark-rapids-sample-job",level:2},{value:"\ud83d\udcc2 Step 1: Change Directory",id:"-step-1-change-directory",level:3},{value:"\ud83d\ude80 Step 2: Execute the Spark RAPIDS Job",id:"-step-2-execute-the-spark-rapids-job",level:3},{value:"\u23f3 What to Expect",id:"-what-to-expect",level:3},{value:"\ud83d\udccb Driver Pod Logs",id:"-driver-pod-logs",level:3},{value:"\ud83e\uddf9 Cleanup Step",id:"-cleanup-step",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components},{Details:r}=n;return r||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"-spark-rapids-on-gpus",children:"\u26a1 Spark RAPIDS on GPUs"})}),"\n",(0,a.jsxs)(n.p,{children:["Welcome to the ",(0,a.jsx)(n.strong,{children:"Spark RAPIDS on GPUs"})," documentation! This guide will help you execute a Spark RAPIDS job on a Kubernetes cluster using GPUs for accelerated data processing. Let's get started! \ud83d\udca1"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"-pre-requisites",children:"\u2705 Pre-requisites"}),"\n",(0,a.jsx)(n.p,{children:"Before you begin, ensure you have the following in place:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\ud83d\ude80 ",(0,a.jsx)(n.strong,{children:"EKS Cluster"}),": Make sure your EKS Cluster is up and running."]}),"\n",(0,a.jsxs)(n.li,{children:["\u2699\ufe0f ",(0,a.jsx)(n.strong,{children:"Karpenter"}),": The Karpenter autoscaler is properly configured."]}),"\n",(0,a.jsxs)(n.li,{children:["\ud83e\uddd1\u200d\ud83d\udcbb ",(0,a.jsx)(n.strong,{children:"Spark Operator"}),": The Spark Operator is installed and ready for use."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Follow this ",(0,a.jsx)(n.a,{href:"https://kubedai.github.io/spark-rapids-on-kubernetes/docs/Deployment/installation",children:"installation guide"})," to set up your cluster and the necessary addons."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"-executing-the-spark-rapids-sample-job",children:"\ud83d\udcbb Executing the Spark RAPIDS Sample Job"}),"\n",(0,a.jsxs)(n.p,{children:["This sample job will demonstrate how to run Spark jobs exclusively on ",(0,a.jsx)(n.strong,{children:"GPUs"})," using the ",(0,a.jsx)(n.strong,{children:"Spark RAPIDS"})," plugin. Here's what the job does:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\ud83c\udfb2 ",(0,a.jsx)(n.strong,{children:"Generates Large DataFrames"}),": The job creates large DataFrames for testing."]}),"\n",(0,a.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,a.jsx)(n.strong,{children:"Joins, Aggregations, and Transformations"}),": It performs data joins, complex aggregations, and transformations on the GPU."]}),"\n",(0,a.jsxs)(n.li,{children:["\ud83d\udee0\ufe0f ",(0,a.jsx)(n.strong,{children:"Explains Execution Plan"}),": The job provides an execution plan for debugging and optimization."]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h3,{id:"-step-1-change-directory",children:"\ud83d\udcc2 Step 1: Change Directory"}),"\n",(0,a.jsx)(n.p,{children:"Navigate to the directory where you've cloned the Spark RAPIDS project:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"cd spark-rapids-on-kubernetes\n"})}),"\n",(0,a.jsx)(n.h3,{id:"-step-2-execute-the-spark-rapids-job",children:"\ud83d\ude80 Step 2: Execute the Spark RAPIDS Job"}),"\n",(0,a.jsx)(n.p,{children:"Ensure you have access to the Kubernetes cluster and are authenticated using kubeconfig. If you haven't authenticated yet, follow the installation steps to set it up."}),"\n",(0,a.jsx)(n.p,{children:"Run the following command to execute the Spark RAPIDS job:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"kubectl apply -f examples/spark-rapids-sample/rapids-sparkoperator-gpu-test.yaml\n"})}),"\n",(0,a.jsx)(n.p,{children:"This will:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Request One Driver Pod on an x86 machine (e.g., m6i.large)."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Request One Executor Pod on a GPU node (e.g., g6.xlarge)."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"-what-to-expect",children:"\u23f3 What to Expect"}),"\n",(0,a.jsx)(n.p,{children:"\u26a1 Node Scaling: The executor pod may take 3-4 minutes to become ready because:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"\ud83d\udd52 Karpenter takes around 50 seconds to provision a new GPU node."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"\ud83d\udc0b Docker Image Pulling may take 1-2 minutes for the executor pod to start."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"\ud83c\udfaf Job Duration: Once everything is set up, the Spark RAPIDS job will complete execution in under 3 minutes."}),"\n",(0,a.jsx)(n.h3,{id:"-driver-pod-logs",children:"\ud83d\udccb Driver Pod Logs"}),"\n",(0,a.jsx)(n.p,{children:"Once the job completes or during the job execution, you can view the driver logs to see the GPU execution plan and verify the performance improvements using RAPIDS."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl logs spark-rapids-gpu-test-driver -n data-eng-team\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Example of a driver log snippet:"})}),"\n",(0,a.jsxs)(r,{children:[(0,a.jsx)("summary",{children:"Click to expand full log (600 lines)"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"++ id -u\n+ myuid=185\n++ id -g\n+ mygid=0\n+ set +e\n++ getent passwd 185\n+ uidentry=\n+ set -e\n+ '[' -z '' ']'\n+ '[' -w /etc/passwd ']'\n+ echo '185:x:185:0:anonymous uid:/opt/spark:/bin/false'\n+ '[' -z /usr/lib/jvm/java-1.8.0-openjdk-amd64 ']'\n+ SPARK_CLASSPATH=':/opt/spark/jars/*'\n+ env\n+ grep SPARK_JAVA_OPT_\n+ sort -t_ -k4 -n\n+ sed 's/[^=]*=\\(.*\\)/\\1/g'\n++ command -v readarray\n+ '[' readarray ']'\n+ readarray -t SPARK_EXECUTOR_JAVA_OPTS\n+ '[' -n '' ']'\n+ '[' -z ']'\n+ '[' -z ']'\n+ '[' -n '' ']'\n+ '[' -z ']'\n+ '[' -z x ']'\n+ SPARK_CLASSPATH='/opt/spark/conf::/opt/spark/jars/*'\n+ SPARK_CLASSPATH='/opt/spark/conf::/opt/spark/jars/*:/opt/spark/work-dir'\n+ case \"$1\" in\n+ shift 1\n+ CMD=(\"$SPARK_HOME/bin/spark-submit\" --conf \"spark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS\" --conf \"spark.executorEnv.SPARK_DRIVER_POD_IP=$SPARK_DRIVER_BIND_ADDRESS\" --deploy-mode client \"$@\")\n+ exec /usr/bin/tini -s -- /opt/spark/bin/spark-submit --conf spark.driver.bindAddress=100.64.216.89 --conf spark.executorEnv.SPARK_DRIVER_POD_IP=100.64.216.89 --deploy-mode client --properties-file /opt/spark/conf/spark.properties --class org.apache.spark.deploy.PythonRunner local:///opt/sparkRapidsPlugin/gpu_rapids_performance_test.py\n24/10/13 04:37:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nINFO:__main__:Configuring Spark session with RAPIDS (GPU-only mode)...\n24/10/13 04:37:29 INFO SparkContext: Running Spark version 3.5.1\n24/10/13 04:37:29 INFO SparkContext: OS info Linux, 6.1.109-118.189.amzn2023.x86_64, amd64\n24/10/13 04:37:29 INFO SparkContext: Java version 1.8.0_422\n24/10/13 04:37:29 INFO ResourceUtils: ==============================================================\n24/10/13 04:37:29 INFO ResourceUtils: No custom resources configured for spark.driver.\n24/10/13 04:37:29 INFO ResourceUtils: ==============================================================\n24/10/13 04:37:29 INFO SparkContext: Submitted application: Spark-RAPIDS-GPU-Only-Performance-Test\n24/10/13 04:37:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(gpu -> name: gpu, amount: 1, script: /opt/sparkRapidsPlugin/getGpusResources.sh, vendor: nvidia.com, cores -> name: cores, amount: 4, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: , memoryOverhead -> name: memoryOverhead, amount: 4096, script: , vendor: , memory -> name: memory, amount: 16384, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0, gpu -> name: gpu, amount: 1.0)\n24/10/13 04:37:29 INFO ResourceProfile: Limiting resource is gpu at 1 tasks per executor\n24/10/13 04:37:29 WARN ResourceUtils: The configuration of cores (exec = 4 task = 1, runnable tasks = 4) will result in wasted resources due to resource gpu limiting the number of runnable tasks per executor to: 1. Please adjust your configuration.\n24/10/13 04:37:29 INFO ResourceProfileManager: Added ResourceProfile id: 0\n24/10/13 04:37:29 INFO SecurityManager: Changing view acls to: 185,spark\n24/10/13 04:37:29 INFO SecurityManager: Changing modify acls to: 185,spark\n24/10/13 04:37:29 INFO SecurityManager: Changing view acls groups to:\n24/10/13 04:37:29 INFO SecurityManager: Changing modify acls groups to:\n24/10/13 04:37:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: 185, spark; groups with view permissions: EMPTY; users with modify permissions: 185, spark; groups with modify permissions: EMPTY\n24/10/13 04:37:29 INFO Utils: Successfully started service 'sparkDriver' on port 7078.\n24/10/13 04:37:29 INFO SparkEnv: Registering MapOutputTracker\n24/10/13 04:37:29 INFO SparkEnv: Registering BlockManagerMaster\n24/10/13 04:37:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n24/10/13 04:37:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n24/10/13 04:37:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n24/10/13 04:37:30 INFO DiskBlockManager: Created local directory at /var/data/spark-8c98f9d9-05b6-4332-9d8e-ef900f191715/blockmgr-e681fb9c-77ae-4e94-a2ae-9a73abc8d0b0\n24/10/13 04:37:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB\n24/10/13 04:37:30 INFO SparkEnv: Registering OutputCommitCoordinator\n24/10/13 04:37:30 INFO JettyUtils: Start Jetty 0.0.0.0:4045 for SparkUI\n24/10/13 04:37:30 INFO Utils: Successfully started service 'SparkUI' on port 4045.\n24/10/13 04:37:30 INFO ShimLoader: Loading shim for Spark version: 3.5.1\n24/10/13 04:37:30 INFO ShimLoader: Complete Spark build info: 3.5.1, https://github.com/apache/spark, HEAD, fd86f85e181fc2dc0f50a096855acf83a6cc5d9c, 2024-02-15T11:24:58Z\n24/10/13 04:37:30 INFO ShimLoader: Scala version: version 2.12.18\n24/10/13 04:37:30 INFO ShimLoader: findURLClassLoader found a URLClassLoader org.apache.spark.util.MutableURLClassLoader@13e3c1c7\n24/10/13 04:37:30 INFO ShimLoader: Updating spark classloader org.apache.spark.util.MutableURLClassLoader@13e3c1c7 with the URLs: jar:file:/opt/spark/jars/rapids-4-spark_2.12-24.08.1.jar!/spark-shared/, jar:file:/opt/spark/jars/rapids-4-spark_2.12-24.08.1.jar!/spark351/\n24/10/13 04:37:30 INFO ShimLoader: Spark classLoader org.apache.spark.util.MutableURLClassLoader@13e3c1c7 updated successfully\n24/10/13 04:37:30 INFO ShimLoader: Updating spark classloader org.apache.spark.util.MutableURLClassLoader@13e3c1c7 with the URLs: jar:file:/opt/spark/jars/rapids-4-spark_2.12-24.08.1.jar!/spark-shared/, jar:file:/opt/spark/jars/rapids-4-spark_2.12-24.08.1.jar!/spark351/\n24/10/13 04:37:30 INFO ShimLoader: Spark classLoader org.apache.spark.util.MutableURLClassLoader@13e3c1c7 updated successfully\n24/10/13 04:37:31 INFO RapidsPluginUtils: RAPIDS Accelerator build: Map(url -> https://github.com/NVIDIA/spark-rapids.git, branch -> HEAD, revision -> 145f4fd3377e708447137673f19ba17839b23aee, version -> 24.08.1, date -> 2024-08-19T03:47:58Z, cudf_version -> 24.08.0, user -> root)\n24/10/13 04:37:31 INFO RapidsPluginUtils: RAPIDS Accelerator JNI build: Map(url -> https://github.com/NVIDIA/spark-rapids-jni.git, branch -> HEAD, gpu_architectures -> 70;75;80;86;90, revision -> 457498d7fbc37f1eefaf0f02ff22f31d47ceca69, version -> 24.08.0, date -> 2024-08-09T01:35:53Z, user -> root)\n24/10/13 04:37:31 INFO RapidsPluginUtils: cudf build: Map(url -> https://github.com/rapidsai/cudf.git, branch -> HEAD, gpu_architectures -> 70;75;80;86;90, revision -> 4afeb5afa7ac483eef8f9a193c73fcce584db92b, version -> 24.08.0, date -> 2024-08-09T01:35:51Z, user -> root)\n24/10/13 04:37:31 INFO RapidsPluginUtils: RAPIDS Accelerator Private Map(url -> https://gitlab-master.nvidia.com/nvspark/spark-rapids-private.git, branch -> HEAD, revision -> 9fac64da220ddd6bf5626bd7bd1dd74c08603eac, version -> 24.08.0, date -> 2024-08-09T08:34:22Z, user -> root)\n24/10/13 04:37:31 WARN RapidsPluginUtils: RAPIDS Accelerator 24.08.1 using cudf 24.08.0, private revision 9fac64da220ddd6bf5626bd7bd1dd74c08603eac\n24/10/13 04:37:31 WARN RapidsPluginUtils: spark.rapids.sql.multiThreadedRead.numThreads is set to 20.\n24/10/13 04:37:31 WARN RapidsPluginUtils: The current setting of spark.task.resource.gpu.amount (1.0) is not ideal to get the best performance from the RAPIDS Accelerator plugin. It's recommended to be 1/{executor core count} unless you have a special use case.\n24/10/13 04:37:31 WARN RapidsPluginUtils: RAPIDS Accelerator is enabled, to disable GPU support set `spark.rapids.sql.enabled` to false.\n24/10/13 04:37:31 WARN RapidsPluginUtils: spark.rapids.sql.explain is set to `ALL`. Set it to 'NONE' to suppress the diagnostics logging about the query placement on the GPU.\n24/10/13 04:37:31 WARN RapidsShuffleInternalManagerBase: Rapids Shuffle Plugin enabled. Multi-threaded shuffle mode (write threads=20, read threads=20). To disable the RAPIDS Shuffle Manager set `spark.rapids.shuffle.enabled` to false\n24/10/13 04:37:31 INFO DriverPluginContainer: Initialized driver component for plugin com.nvidia.spark.SQLPlugin.\n24/10/13 04:37:31 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file\n24/10/13 04:37:33 INFO ExecutorPodsAllocator: Going to request 1 executors from Kubernetes for ResourceProfile Id: 0, target: 1, known: 0, sharedSlotFromPendingPods: 2147483647.\n24/10/13 04:37:33 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs\n24/10/13 04:37:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.\n24/10/13 04:37:33 INFO NettyBlockTransferService: Server created on spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc 100.64.216.89:7079\n24/10/13 04:37:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n24/10/13 04:37:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc, 7079, None)\n24/10/13 04:37:33 INFO BlockManagerMasterEndpoint: Registering block manager spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc:7079 with 912.3 MiB RAM, BlockManagerId(driver, spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc, 7079, None)\n24/10/13 04:37:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc, 7079, None)\n24/10/13 04:37:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc, 7079, None)\n24/10/13 04:37:33 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script\n24/10/13 04:38:03 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\nINFO:__main__:Spark session initialized successfully (GPU-only).\nINFO:__main__:Creating large DataFrames with multiple columns for join operation...\n24/10/13 04:38:05 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n24/10/13 04:38:05 INFO SharedState: Warehouse path is 'file:/opt/spark/work-dir/spark-warehouse'.\nINFO:__main__:Performing a GPU-accelerated join between two large DataFrames...\nINFO:__main__:Performing aggregation on the joined DataFrame using GPU...\nINFO:__main__:Running SQL query with aggregation and filtering, explaining execution plan...\n24/10/13 04:38:09 INFO GpuOverrides: Plan conversion to the GPU took 43.05 ms\n24/10/13 04:38:09 INFO GpuOverrides: GPU plan transition optimization took 9.75 ms\n24/10/13 04:38:10 WARN GpuOverrides:\n*Exec <SortExec> will run on GPU\n*Expression <SortOrder> total_amount1#74 DESC NULLS LAST will run on GPU\n*Exec <ShuffleExchangeExec> will run on GPU\n    *Partitioning <RangePartitioning> will run on GPU\n    *Expression <SortOrder> total_amount1#74 DESC NULLS LAST will run on GPU\n    *Exec <FilterExec> will run on GPU\n    *Expression <And> ((isnotnull(total_amount1#74) AND isnotnull(total_amount2#75)) AND ((total_amount1#74 > 5000.0) AND (total_amount2#75 > 10000.0))) will run on GPU\n        *Expression <And> (isnotnull(total_amount1#74) AND isnotnull(total_amount2#75)) will run on GPU\n        *Expression <IsNotNull> isnotnull(total_amount1#74) will run on GPU\n        *Expression <IsNotNull> isnotnull(total_amount2#75) will run on GPU\n        *Expression <And> ((total_amount1#74 > 5000.0) AND (total_amount2#75 > 10000.0)) will run on GPU\n        *Expression <GreaterThan> (total_amount1#74 > 5000.0) will run on GPU\n        *Expression <GreaterThan> (total_amount2#75 > 10000.0) will run on GPU\n    *Exec <HashAggregateExec> will run on GPU\n        *Expression <AggregateExpression> sum(amount1#11) will run on GPU\n        *Expression <Sum> sum(amount1#11) will run on GPU\n        *Expression <AggregateExpression> sum(amount2#33) will run on GPU\n        *Expression <Sum> sum(amount2#33) will run on GPU\n        *Expression <Alias> sum(amount1#11)#78 AS total_amount1#74 will run on GPU\n        *Expression <Alias> sum(amount2#33)#79 AS total_amount2#75 will run on GPU\n        *Exec <ShuffleExchangeExec> will run on GPU\n        *Partitioning <HashPartitioning> will run on GPU\n        *Exec <HashAggregateExec> will run on GPU\n            *Expression <AggregateExpression> partial_sum(amount1#11) will run on GPU\n            *Expression <Sum> sum(amount1#11) will run on GPU\n            *Expression <AggregateExpression> partial_sum(amount2#33) will run on GPU\n            *Expression <Sum> sum(amount2#33) will run on GPU\n            *Exec <ProjectExec> will run on GPU\n            *Exec <SortMergeJoinExec> will run on GPU\n                #Exec <SortExec> could run on GPU but is going to be removed because replacing sortMergeJoin with shuffleHashJoin\n                #Expression <SortOrder> id1#2L ASC NULLS FIRST could run on GPU but is going to be removed because parent plan is removed\n                *Exec <ShuffleExchangeExec> will run on GPU\n                    *Partitioning <HashPartitioning> will run on GPU\n                    *Exec <ProjectExec> will run on GPU\n                    *Expression <Alias> (rand(-4580673251311449240) * 1000.0) AS amount1#11 will run on GPU\n                        *Expression <Multiply> (rand(-4580673251311449240) * 1000.0) will run on GPU\n                        *Expression <Rand> rand(-4580673251311449240) will run on GPU\n                    *Exec <ProjectExec> will run on GPU\n                        *Expression <Alias> id#0L AS id1#2L will run on GPU\n                        *Expression <Alias> CASE WHEN (rand(-162214519805210713) > 0.5) THEN A ELSE B END AS category1#7 will run on GPU\n                        *Expression <CaseWhen> CASE WHEN (rand(-162214519805210713) > 0.5) THEN A ELSE B END will run on GPU\n                            *Expression <GreaterThan> (rand(-162214519805210713) > 0.5) will run on GPU\n                            *Expression <Rand> rand(-162214519805210713) will run on GPU\n                        *Exec <RangeExec> will run on GPU\n                #Exec <SortExec> could run on GPU but is going to be removed because replacing sortMergeJoin with shuffleHashJoin\n                #Expression <SortOrder> id2#24L ASC NULLS FIRST could run on GPU but is going to be removed because parent plan is removed\n                *Exec <ShuffleExchangeExec> will run on GPU\n                    *Partitioning <HashPartitioning> will run on GPU\n                    *Exec <ProjectExec> will run on GPU\n                    *Expression <Alias> (rand(-3531675506200722645) * 2000.0) AS amount2#33 will run on GPU\n                        *Expression <Multiply> (rand(-3531675506200722645) * 2000.0) will run on GPU\n                        *Expression <Rand> rand(-3531675506200722645) will run on GPU\n                    *Exec <ProjectExec> will run on GPU\n                        *Expression <Alias> id#22L AS id2#24L will run on GPU\n                        *Expression <Alias> CASE WHEN (rand(8868201660340206917) > 0.5) THEN X ELSE Y END AS category2#29 will run on GPU\n                        *Expression <CaseWhen> CASE WHEN (rand(8868201660340206917) > 0.5) THEN X ELSE Y END will run on GPU\n                            *Expression <GreaterThan> (rand(8868201660340206917) > 0.5) will run on GPU\n                            *Expression <Rand> rand(8868201660340206917) will run on GPU\n                        *Exec <RangeExec> will run on GPU\n\n...\n...\n24/10/13 04:40:11 INFO GpuOverrides: Plan conversion to the GPU took 5.93 ms\n24/10/13 04:40:11 INFO GpuOverrides: GPU plan transition optimization took 6.83 ms\n24/10/13 04:40:11 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n24/10/13 04:40:11 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n24/10/13 04:40:11 INFO DAGScheduler: Final stage: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0)\n24/10/13 04:40:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\n24/10/13 04:40:11 INFO DAGScheduler: Missing parents: List()\n24/10/13 04:40:11 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[38] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n24/10/13 04:40:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 66.5 KiB, free 912.1 MiB)\n24/10/13 04:40:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 912.1 MiB)\n24/10/13 04:40:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc:7079 (size: 29.3 KiB, free: 912.2 MiB)\n24/10/13 04:40:11 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585\n24/10/13 04:40:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[38] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n24/10/13 04:40:11 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n24/10/13 04:40:11 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 14) (100.64.144.54, executor 1, partition 0, NODE_LOCAL, 7643 bytes) taskResourceAssignments Map(gpu -> [name: gpu, addresses: 0])\n24/10/13 04:40:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 100.64.144.54:40463 (size: 29.3 KiB, free: 9.0 GiB)\n24/10/13 04:40:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 100.64.144.54:39980\n24/10/13 04:40:12 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 14) in 497 ms on 100.64.144.54 (executor 1) (1/1)\n24/10/13 04:40:12 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool\n24/10/13 04:40:12 INFO DAGScheduler: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0) finished in 0.551 s\n24/10/13 04:40:12 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n24/10/13 04:40:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished\n24/10/13 04:40:12 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.573601 s\n24/10/13 04:40:12 INFO CodeGenerator: Code generated in 337.051601 ms\n+---------+---------+--------------------+--------------------+\n|category1|category2|       total_amount1|       total_amount2|\n+---------+---------+--------------------+--------------------+\n|        B|        Y|1.2509678979152799E9|2.5029069984810357E9|\n|        B|        X|1.2505991236420312E9| 2.498830686819548E9|\n|        A|        Y|1.2502600486702027E9|2.4991205284351277E9|\n|        A|        X|1.2500673333482282E9| 2.498443896974076E9|\n+---------+---------+--------------------+--------------------+\n\nINFO:__main__:Stopping the Spark session.\n24/10/13 04:40:12 INFO SparkContext: SparkContext is stopping with exitCode 0.\n24/10/13 04:40:12 INFO SparkUI: Stopped Spark web UI at http://spark-rapids-gpu-test-5b721692842aaf82-driver-svc.data-eng-team.svc:4045\n24/10/13 04:40:12 INFO KubernetesClusterSchedulerBackend: Shutting down all executors\n24/10/13 04:40:12 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down\n24/10/13 04:40:12 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.\n24/10/13 04:40:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n24/10/13 04:40:12 INFO MemoryStore: MemoryStore cleared\n24/10/13 04:40:12 INFO BlockManager: BlockManager stopped\n24/10/13 04:40:12 INFO BlockManagerMaster: BlockManagerMaster stopped\n24/10/13 04:40:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n24/10/13 04:40:12 INFO SparkContext: Successfully stopped SparkContext\nINFO:__main__:Spark session stopped successfully.\n24/10/13 04:40:13 INFO ShutdownHookManager: Shutdown hook called\n24/10/13 04:40:13 INFO ShutdownHookManager: Deleting directory /var/data/spark-8c98f9d9-05b6-4332-9d8e-ef900f191715/spark-be20bd85-675f-4447-8564-60ff5d990034/pyspark-d4aee595-e3ed-48ed-abf8-3a6e0a5733b7\n24/10/13 04:40:13 INFO ShutdownHookManager: Deleting directory /var/data/spark-8c98f9d9-05b6-4332-9d8e-ef900f191715/spark-be20bd85-675f-4447-8564-60ff5d990034\n24/10/13 04:40:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-a227b906-04fe-4ace-a08b-9dfb8d8c0364\n"})})]}),"\n",(0,a.jsx)(n.h2,{id:"-cleanup-step",children:"\ud83e\uddf9 Cleanup Step"}),"\n",(0,a.jsx)(n.p,{children:"Once you're done with the job execution and have reviewed the results, you can clean up the resources created by the Spark RAPIDS job to free up cluster resources."}),"\n",(0,a.jsx)(n.p,{children:"To delete the job and its associated resources, run the following command:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl delete -f examples/spark-rapids-sample/rapids-sparkoperator-gpu-test.yaml\n"})}),"\n",(0,a.jsx)(n.p,{children:"This will:"}),"\n",(0,a.jsx)(n.p,{children:"\ud83d\uddd1\ufe0f Remove the driver and executor pods created by the job."}),"\n",(0,a.jsx)(n.p,{children:"\ud83d\udee0\ufe0f Free up the GPU resources provisioned by Karpenter."}),"\n",(0,a.jsxs)(n.admonition,{type:"warning",children:[(0,a.jsxs)(n.p,{children:["Before you shut down your laptop and call it a day, ",(0,a.jsx)(n.strong,{children:"make sure"})," that those ",(0,a.jsx)(n.strong,{children:"GPU nodes"})," have scaled down! \ud83d\udcb8"]}),(0,a.jsx)(n.p,{children:"If you don't, the GPUs will still be running in the cloud, quietly adding to your bill while you're binge-watching your favorite show. \ud83e\udd11"}),(0,a.jsx)(n.p,{children:"So, save your wallet! Double-check everything with:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl get nodes\n"})}),(0,a.jsx)(n.p,{children:"Your future self (and bank account) will thank you! \ud83d\ude05"})]}),"\n",(0,a.jsx)(n.p,{children:"That's it! \ud83c\udf89 You've successfully executed a Spark RAPIDS job on Kubernetes using GPUs for accelerated processing. \ud83d\ude80"})]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>i});var a=r(6540);const s={},t=a.createContext(s);function o(e){const n=a.useContext(t);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);